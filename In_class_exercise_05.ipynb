{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of In_class_exercise_05.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pragnareddy96/Battu_INFO5731_Spring2020/blob/master/In_class_exercise_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7TahL04sVvR",
        "colab_type": "text"
      },
      "source": [
        "# **The fifth in-class-exercise**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejyZITr8sjnh",
        "colab_type": "text"
      },
      "source": [
        "## **1. Rule-based information extraction**\n",
        "\n",
        "Use any keywords related to data science, natural language processing, machine learning to search from google scholar, get the **titles** of 100 articles (either by web scraping or manually) about this topic, define a set of patterns to extract the research questions/problems, methods/algorithms/models, datasets, applications, or any other important information about this topic. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvR_O9D8sOUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install scholarly\n",
        "import requests\n",
        "import urllib\n",
        "#from bs4 import BeautifulSoup\n",
        "import re \n",
        "import string \n",
        "import nltk \n",
        "import scholarly\n",
        "import spacy \n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import math \n",
        "from tqdm import tqdm\n",
        "from spacy.matcher import Matcher \n",
        "from spacy.tokens import Span \n",
        "from spacy import displacy \n",
        "pd.set_option('display.max_colwidth', 100)\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "search_pubs_query= scholarly.search_keyword('data')\n",
        "select = next(search_pubs_query).fill()\n",
        "hundred_articles=[pub.bib['name'] for pub in author.publications][0:100]\n",
        "print(hundred_articles)\n",
        "matches = matcher(nlp.vocab)\n",
        "pattern0 = [{\"TEXT\":  \"proble[m|ms]\"}]\n",
        "pattern1 = [{\"TEXT\":  \"metho[d|ds]\"}]\n",
        "pattern2 = [{\"TEXT\":  \"researc[h|hes]\"}]\n",
        "pattern3 = [{\"TEXT\": \"mode[l|ls]\"}]\n",
        "pattern4 = [{\"TEXT\":  \"datase[t|ts]\"}]\n",
        "pattern5 = [{\"TEXT\":  \"applicatio[n|ns]\"}]\n",
        "pattern6 = [{\"TEXT\":  \"algorith[m|ms]\"}]\n",
        "matcher.add(\"problem\",pattern0)\n",
        "matcher.add(\"method\",pattern1)\n",
        "matcher.add(\"research\",pattern2)\n",
        "matcher.add(\"model\",pattern3)\n",
        "matcher.add(\"dataset\",pattern4)\n",
        "matcher.add(\"application\",pattern5)\n",
        "matcher.add(\"algorithm\",pattern6)\n",
        "\n",
        "for name in hundred_articles:\n",
        " doc = nlp(name)\n",
        " matches = matcher(doc)\n",
        " if matches:\n",
        "   for match_id, start, end in matches:\n",
        "    string_id = nlp.vocab.strings[match_id] \n",
        "    print(match_id, string_id, start, end)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#response = requests.get(link)\n",
        "#soup = BeautifulSoup(response.text, 'lxml'\n",
        "\n",
        "#for g in list(soup.find_all(class_='gs_rt'))[:100]:\n",
        "#print(response.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq_7VGmrsum4",
        "colab_type": "text"
      },
      "source": [
        "## **2. Domain-specific information extraction**\n",
        "\n",
        "For the legal case used in the data cleaning exercise: [01-05-1 Adams v Tanner.txt](https://raw.githubusercontent.com/unt-iialab/INFO5731_Spring2020/master/In_class_exercise/01-05-1%20%20Adams%20v%20Tanner.txt), use [legalNLP](https://lexpredict-lexnlp.readthedocs.io/en/latest/modules/extract/extract.html#nlp-based-extraction-methods) to extract the following inforation from the text (if the information is not exist, just print None):\n",
        "\n",
        "(1) acts, e.g., “section 1 of the Advancing Hope Act, 1986”\n",
        "\n",
        "(2) amounts, e.g., “ten pounds” or “5.8 megawatts”\n",
        "\n",
        "(3) citations, e.g., “10 U.S. 100” or “1998 S. Ct. 1”\n",
        "\n",
        "(4) companies, e.g., “Lexpredict LLC”\n",
        "\n",
        "(5) conditions, e.g., “subject to …” or “unless and until …”\n",
        "\n",
        "(6) constraints, e.g., “no more than”\n",
        "\n",
        "(7) copyright, e.g., “(C) Copyright 2000 Acme”\n",
        "\n",
        "(8) courts, e.g., “Supreme Court of New York”\n",
        "\n",
        "(9) CUSIP, e.g., “392690QT3”\n",
        "\n",
        "(10) dates, e.g., “June 1, 2017” or “2018-01-01”\n",
        "\n",
        "(11) definitions, e.g., “Term shall mean …”\n",
        "\n",
        "(12) distances, e.g., “fifteen miles”\n",
        "\n",
        "(13) durations, e.g., “ten years” or “thirty days”\n",
        "\n",
        "(14) geographic and geopolitical entities, e.g., “New York” or “Norway”\n",
        "\n",
        "(15) money and currency usages, e.g., “$5” or “10 Euro”\n",
        "\n",
        "(16) percents and rates, e.g., “10%” or “50 bps”\n",
        "\n",
        "(17) PII, e.g., “212-212-2121” or “999-999-9999”\n",
        "\n",
        "(18) ratios, e.g.,” 3:1” or “four to three”\n",
        "\n",
        "(19) regulations, e.g., “32 CFR 170”\n",
        "\n",
        "(20) trademarks, e.g., “MyApp (TM)”\n",
        "\n",
        "(21) URLs, e.g., “http://acme.com/”\n",
        "\n",
        "(22) addresses, e.g., “1999 Mount Read Blvd, Rochester, NY, USA, 14615”\n",
        "\n",
        "(23) persons, e.g., “John Doe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT4vr2dML2Fu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!git clone https://github.com/LexPredict/lexpredict-lexnlp.git\n",
        "#!bash -c 'mv lexpredict-lexnlp/lexnlp .'\n",
        "#!pip install -r lexpredict-lexnlp/python-requirements.txt\n",
        "\n",
        "import requests,os\n",
        "import pandas,urllib.request\n",
        "import nltk\n",
        "import lexnlp.extract.en.entities.nltk_re\n",
        "from lexnlp.extract.en.citations import get_citations, get_citation_annotations\n",
        "import lexnlp.extract.en.acts\n",
        "import lexnlp.extract.en.conditions\n",
        "import lexnlp.extract.en.constraints\n",
        "import lexnlp.extract.en.copyright\n",
        "import lexnlp.extract.en.courts\n",
        "from lexnlp.extract.en.dict_entities import entity_config, add_alias_to_entity\n",
        "from lexnlp.extract.en.cusip import get_cusip_list\n",
        "import lexnlp.extract.en.dates\n",
        "import lexnlp.extract.en.definitions\n",
        "import lexnlp.extract.en.distances\n",
        "from lexnlp.extract.en.geoentities import get_geoentities, load_entities_dict_by_path\n",
        "import lexnlp.extract.en.money\n",
        "import lexnlp.extract.en.percents\n",
        "import lexnlp.extract.en.pii\n",
        "import lexnlp.extract.en.ratios\n",
        "import lexnlp.extract.en.regulations\n",
        "import lexnlp.extract.en.trademarks\n",
        "import lexnlp.extract.en.urls\n",
        "import requests\n",
        "from lexnlp.extract.en.dates import get_dates\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "link = \"https://raw.githubusercontent.com/unt-iialab/INFO5731_Spring2020/master/In_class_exercise/01-05-1%20%20Adams%20v%20Tanner.txt\"\n",
        "text1 = requests.get(link) \n",
        "text2 = text1.text \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB3j3xaqNrZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(lexnlp.extract.en.dates.get_dates(text2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXtA7tyMc9vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lexnlp.extract.en.citations import get_citations\n",
        "\n",
        "list(lexnlp.extract.en.citations.get_citations(text2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaVOfJVDQWSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(list(lexnlp.extract.en.copyright.get_copyright(text2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTLsFNPCQgBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(list(lexnlp.extract.en.entities.nltk_re.get_companies(text2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ko24V4TRBl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "court_df = pandas.read_csv(\"https://raw.githubusercontent.com/LexPredict/lexpredict-legal-dictionary/1.0.5/en/legal/us_courts.csv\")\n",
        "# Create config objects\n",
        "court_config_data = []\n",
        "for _, row in court_df.iterrows():\n",
        "    c = entity_config(row[\"Court ID\"], row[\"Court Name\"], 0, row[\"Alias\"].split(\";\") if not pandas.isnull(row[\"Alias\"]) else [])\n",
        "    court_config_data.append(c)\n",
        "for entity, alias in lexnlp.extract.en.courts.get_courts(text2, court_config_data):\n",
        "    print(\"entity=\", entity)\n",
        "    print(\"alias=\", alias)\n",
        "entity= (98, 'Eastern District of Virginia', 0, [('Eastern District of Virginia', None, False, None), ('E.D. Va.', None, False, None)])\n",
        "alias= ('E.D. Va.', None, False, None)\n",
        "entity= (70, 'Southern District of New York', 0, [('Southern District of New York', None, False, None), ('S.D.N.Y.', None, False, None)])\n",
        "alias= ('S.D.N.Y.', None, False, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONG7INQQePSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lexnlp.extract.en.durations import get_durations\n",
        "\n",
        "list(lexnlp.extract.en.durations.get_durations(text2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI5gRJove_RC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lexnlp.extract.en.money import get_money\n",
        "\n",
        "\n",
        "list(lexnlp.extract.en.money.get_money(text2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO3PVWtJitDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lexnlp.extract.en.constraints import get_constraints\n",
        "constraints = list(get_constraints(text2))\n",
        "print(list(lexnlp.extract.en.constraints.get_constraints(text2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs2zs5yLkugU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lexnlp.extract.en.percents import get_percents\n",
        "\n",
        "list(lexnlp.extract.en.percents.get_percents(text2))\n",
        "#print('none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVYg-yylmCwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lexnlp.extract.en.urls import get_urls\n",
        "\n",
        "list(lexnlp.extract.en.urls.get_urls(text2))\n",
        "#print('none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6DNnYjZmMTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lexnlp.extract.en.pii import get_pii\n",
        "\n",
        "list(lexnlp.extract.en.pii.get_pii(text2))\n",
        "#print('none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0Bi2n2SmjmJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lexnlp.extract.en.conditions import get_conditions\n",
        "\n",
        "list(lexnlp.extract.en.conditions.get_conditions(text2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4GnH2sGqWBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lexnlp.extract.en.acts import get_acts\n",
        "\n",
        "list(lexnlp.extract.en.acts.get_acts(text2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vvd1AyIZqnnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lexnlp.extract.en.cusip import get_cusip\n",
        "\n",
        "list(lexnlp.extract.en.cusip.get_cusip(text2))\n",
        "print(\"none\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic1jraYHrw17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lexnlp.extract.en.definitions import get_definitions\n",
        "\n",
        "list(lexnlp.extract.en.definitions.get_definitions(text2))\n",
        "#print('none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wxnr1w14sSm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lexnlp.extract.en.distances import get_distances\n",
        "\n",
        "list(lexnlp.extract.en.distances.get_distances(text2))\n",
        "#print('none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKk1IQ-jt-wi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lexnlp.extract.en.percents import get_percents\n",
        "\n",
        "list(lexnlp.extract.en.percents.get_percents(text2))\n",
        "#print('none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prZJTDMIuaMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lexnlp.extract.en.ratios import get_ratios\n",
        "\n",
        "list(lexnlp.extract.en.ratios.get_ratios(text2))\n",
        "#print('none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duozFbqKukJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lexnlp.extract.en.regulations import get_regulations\n",
        "\n",
        "list(lexnlp.extract.en.regulations.get_regulations(text2))\n",
        "#print('none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0bi2KAEuwa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lexnlp.extract.en.trademarks import get_trademarks\n",
        "\n",
        "list(lexnlp.extract.en.trademarks.get_trademarks(text2))\n",
        "#print('none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ulr9BOeSu8pj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from lexnlp.extract.en.urls import get_urls\n",
        "\n",
        "list(lexnlp.extract.en.urls.get_urls(text2))\n",
        "#print('none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VntRUFhhvRuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(list(lexnlp.extract.en.amounts.get_amounts(text2)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}